{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SETTINGS ###\n",
    "project_dir = '/homes_unix/agillig/github_repos/ginna' #specify your path to the github repository\n",
    "\n",
    "n_perm = 100 # number of permutations per batch; reduced for the sake of the example (publication: 10,000)\n",
    "n_batches = 1 #Â number of batches. can be useful to split the work in a cluster environment\n",
    "\n",
    "compute_all_rsns = False # if True, compute all RSNs; if False, compute only RSN01 as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, project_dir + '/code')\n",
    "\n",
    "import func_toolbox as ftools\n",
    "from func_toolbox import fetch_neurosynth_data\n",
    "from nilearn import image\n",
    "import null_parcellations\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "neurosynth_terms_file = project_dir + '/data/terms/BCS_3D.csv'\n",
    "os.makedirs(Path(neurosynth_terms_file).parent, exist_ok=True)\n",
    "\n",
    "# download the file from the Pacela et al. 2021 paper repo \n",
    "# https://github.com/vale-pak/BCS\n",
    "\n",
    "if not os.path.exists(neurosynth_terms_file):\n",
    "    fetch_neurosynth_data(f'{project_dir}/data')\n",
    "\n",
    "# https://github.com/vale-pak/BCS/blob/main/BCS_3D.csv\n",
    "df = pd.read_csv(neurosynth_terms_file, sep = ',')\n",
    "\n",
    "neurosynth_terms = df['Functions']\n",
    "\n",
    "fcu = ftools.Utilities()\n",
    "atlas_str = \"aicha-aal3\"\n",
    "\n",
    "fcu.set_project_dir(project_dir)\n",
    "fcu.set_atlas_name(atlas_str)\n",
    "\n",
    "# create a new directory for the analysis\n",
    "analysis_dir = project_dir + f'/analysis/mean_RSNs_{atlas_str}'\n",
    "os.makedirs(analysis_dir, exist_ok=True)\n",
    "\n",
    "mip_rsn_dir = project_dir + f'/Results/mip/mip_rsn_parcellated/aicha'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create atlas : aicha + AAL cerebellum / BG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcellation_atlas_file = f'{project_dir}/data/parcellation_atlases/aicha-aal3/parcels_aicha-aal3.nii.gz'\n",
    "\n",
    "# the atlas is already present in the github repository\n",
    "if not os.path.exists(parcellation_atlas_file):\n",
    "        atlases_dir = ''\n",
    "        file_cortical = atlases_dir + '/AICHA_v2_websiteC/AICHA.nii'\n",
    "        file_subcortical = atlases_dir + '/AAL3/AAL3v1.nii'\n",
    "\n",
    "        cortical_img = image.load_img(file_cortical)\n",
    "        new_data = np.zeros_like(cortical_img.get_fdata(), dtype = 'int32')\n",
    "\n",
    "        cortical_data = image.load_img(file_cortical).get_fdata()\n",
    "        subcortical_data = image.load_img(file_subcortical).get_fdata()\n",
    "        # cortical\n",
    "        max_cortical = np.max(cortical_data)\n",
    "        for i, value in enumerate(np.unique(cortical_data)[1:]):\n",
    "                new_data[cortical_data == value] = i + 1 \n",
    "        # cerebellum\n",
    "        # indices : from 95-120 for cerebellum; 121-170 for subcrotcial/brainstem\n",
    "        for i, value in enumerate([l for l in range(95 , 121)]):\n",
    "                new_data[subcortical_data == value] = max_cortical + i + 1 \n",
    "\n",
    "        new_img = image.new_img_like(cortical_img, new_data)\n",
    "        out_map = parcellation_atlas_file\n",
    "        os.makedirs(os.path.dirname(out_map), exist_ok=True)\n",
    "        new_img.to_filename(out_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to GINNA zstat maps\n",
    "atlas_dir = f'{project_dir}/atlas/zmaps'\n",
    "rsn_files = [os.path.join(atlas_dir, f) for f in os.listdir(atlas_dir) if f.endswith('.nii')]\n",
    "rsn_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Create A 4D volume with all 506 maps of the model\n",
    "# this may take a few min\n",
    "terms_maps_dir = f'{project_dir}/data/dataset'\n",
    "terms_maps_files = [os.path.join(terms_maps_dir, f) for f in os.listdir(terms_maps_dir) if f.endswith('.nii.gz')]\n",
    "terms_maps_files.sort()\n",
    "\n",
    "out_dir = f'{terms_maps_dir}/concatenated'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "out_name = out_dir + '/dataset_concatenated.nii.gz'\n",
    "if os.path.isfile(out_name) == False:\n",
    "    image.concat_imgs(terms_maps_files).to_filename(out_name)\n",
    "concat_ds = image.load_img(out_name)\n",
    "\n",
    "terms_maps_files_all = terms_maps_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create & retrieve parcellated 506 meta analytic maps\n",
    "# should also take a few minutes, but needs to be done only once\n",
    "\n",
    "n_terms = concat_ds.shape[3]\n",
    "\n",
    "parcellated_dataset_dir = f'{project_dir}/data/dataset/parcellated/{atlas_str}'\n",
    "os.makedirs(parcellated_dataset_dir, exist_ok=True)\n",
    "\n",
    "parcellated_dataset_file = os.path.join(parcellated_dataset_dir, f'neurosynthterms_parcellations_{atlas_str}.csv')\n",
    "\n",
    "parcellated = []\n",
    "\n",
    "if os.path.isfile(parcellated_dataset_file) == False:\n",
    "    for t in range(n_terms):\n",
    "        temp_img = image.index_img(concat_ds, t)\n",
    "        parcellated.append(fcu.parcellate(temp_img, atlas=parcellation_atlas_file))\n",
    "\n",
    "    parcellated = np.array(parcellated).squeeze()\n",
    "    terms = neurosynth_terms.values\n",
    "    # print(parcellated.shape)\n",
    "    parcels = [i for i in range(1, parcellated.shape[1] +1)]\n",
    "    dataset_parcellated = pd.DataFrame(parcellated, index=terms, columns = parcels)\n",
    "    dataset_parcellated.to_csv(parcellated_dataset_file)\n",
    "else:\n",
    "    dataset_parcellated = pd.read_csv(parcellated_dataset_file, sep = ',', index_col = 0)\n",
    "\n",
    "fcu.dataset_parcellated = dataset_parcellated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial correlation between RSNs & the Neurosynth maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each rsn, compute the spatial correlation with the 506 meta analytic maps (parcellated)\n",
    "atlas_img = '/homes_unix/agillig/Atlases/RSN_N41_zNpair_clean1.nii'\n",
    "parcellation_dir = analysis_dir + '/parcellations'\n",
    "os.makedirs(parcellation_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "rsn_str = pd.DataFrame(rsn_files).iloc[:,0].str.split('/').str[-1].str[-6:-4]\n",
    "\n",
    "if compute_all_rsns == False:\n",
    "    rsn_str = [rsn_str[0]] #limited to RSN01 to reduce computation time\n",
    "\n",
    "for i, rsn in enumerate(rsn_str):\n",
    "    parcellation_file = parcellation_dir + f'/rsn-{rsn}/rsn-{rsn}_unique_parcellated.csv'\n",
    "    os.makedirs(os.path.dirname(parcellation_file), exist_ok=True)\n",
    "\n",
    "    index = int(rsn) - 1\n",
    "    # tmp_data = image.index_img(atlas_img, index)\n",
    "    # affine = tmp_img.affine\n",
    "    if os.path.isfile(parcellation_file) == False:\n",
    "        tmp_img = image.load_img(rsn_files[index])\n",
    "        tmp_parcellatd = fcu.parcellate(tmp_img, atlas=parcellation_atlas_file)\n",
    "        np.savetxt(parcellation_file, tmp_parcellatd, delimiter = ',')\n",
    "    data = np.loadtxt(parcellation_file, delimiter = ',')\n",
    "\n",
    "\n",
    "    corr_temp = [np.corrcoef(data, dataset_parcellated.iloc[j,:])[1,0] for j in range(n_terms)]\n",
    "    \n",
    "    results[rsn] = {'term': neurosynth_terms, 'spatial_correlation': corr_temp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non parametric statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rsn 01\n",
      "batch 1\n",
      "generating 100 surrogates\n",
      "elapsed time: 26.73 s\n",
      "saving surrogate maps to /homes_unix/agillig/github_repos/ginna/analysis/mean_RSNs_aicha-aal3/null_parcellations/rsn-01/rsn-01_null_parcellations_batch-01_of_1.csv\n",
      "processing rsn 01\n",
      "saving file\n"
     ]
    }
   ],
   "source": [
    "# null_projections = {}\n",
    "# use brainsmash to generate surrogate data that preserves spatial autocorrelation (Burt, 2020)\n",
    "# https://github.com/murraylab/brainsmash: cf null_parcellations.py\n",
    "\n",
    "# once computed, for each rsn, compute the correlation of the null parcellations with the 506 meta analytic maps (parcellated)\n",
    "\n",
    "for rsn in rsn_str:\n",
    "    null_parcellations.generate_null(1, project_dir, n_perm=n_perm, n_batches=n_batches)\n",
    "    null_distr = fcu.compute_correlation_null(rsn='01', n_perm=n_perm, n_batches=n_batches, overwrite=True) #set overwrite to False if you have already computed the null distributions\n",
    "\n",
    "    p, pcor = fcu.compute_pvalues(results[rsn]['spatial_correlation'], null_distr)\n",
    "\n",
    "    results[rsn]['p'] = p\n",
    "    results[rsn]['pcor'] = pcor\n",
    "    results[rsn]['is_significant'] = (results[rsn]['pcor'] < 0.05).tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results summary for RSN01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>spatial_correlation</th>\n",
       "      <th>p</th>\n",
       "      <th>pcor</th>\n",
       "      <th>is_significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>mnemonic</td>\n",
       "      <td>0.399498</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.099010</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>retrieval</td>\n",
       "      <td>0.376930</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>recollection</td>\n",
       "      <td>0.371836</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.158416</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>thoughts</td>\n",
       "      <td>0.318702</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>memory_retrieval</td>\n",
       "      <td>0.317122</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>movement</td>\n",
       "      <td>-0.105119</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>sensorimotor</td>\n",
       "      <td>-0.105715</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>motor_imagery</td>\n",
       "      <td>-0.107935</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>movements</td>\n",
       "      <td>-0.117540</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>motor</td>\n",
       "      <td>-0.119462</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 term  spatial_correlation         p      pcor  is_significant\n",
       "255          mnemonic             0.399498  0.009901  0.099010           False\n",
       "362         retrieval             0.376930  0.009901  0.148515           False\n",
       "349      recollection             0.371836  0.009901  0.158416           False\n",
       "457          thoughts             0.318702  0.019802  0.336634           False\n",
       "249  memory_retrieval             0.317122  0.009901  0.336634           False\n",
       "..                ...                  ...       ...       ...             ...\n",
       "272          movement            -0.105119  0.653465  1.000000           False\n",
       "390      sensorimotor            -0.105715  0.683168  1.000000           False\n",
       "267     motor_imagery            -0.107935  0.683168  1.000000           False\n",
       "273         movements            -0.117540  0.673267  1.000000           False\n",
       "265             motor            -0.119462  0.683168  1.000000           False\n",
       "\n",
       "[506 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_table = pd.DataFrame.from_dict(results['01']).sort_values(by='spatial_correlation', ascending=False)\n",
    "res_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
