{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: carry out a hierarchical dirichlet process analysis to identify topics shared accross meta analytic terms, thus clustering them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/homes_unix/agillig/github_repos/ginna'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func_toolbox import fetch_neurosynth_data\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from nimare.extract import download_abstracts, fetch_neuroquery, fetch_neurosynth\n",
    "from nimare.io import convert_neurosynth_to_dataset\n",
    "\n",
    "seed = 15011999\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Semantic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: gathering text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. list of all included articles for each of the 506 meta-analytic terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. extract text data from each article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we will just extract the whole neurosynth db using nimare, ask valentina for the exact list of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nimare.extract.utils:Dataset found in /scratch/agillig/db/neurosynth\n",
      "\n",
      "INFO:nimare.extract.extract:Searching for any feature files matching the following criteria: [('source-abstract', 'vocab-terms', 'data-neurosynth', 'version-7')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data-neurosynth_version-7_coordinates.tsv.gz\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_metadata.tsv.gz\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-terms_source-abstract_type-tfidf_features.npz\n",
      "File exists and overwrite is False. Skipping.\n",
      "Downloading data-neurosynth_version-7_vocab-terms_vocabulary.txt\n",
      "File exists and overwrite is False. Skipping.\n",
      "[{'coordinates': '/scratch/agillig/db/neurosynth/data-neurosynth_version-7_coordinates.tsv.gz',\n",
      "  'features': [{'features': '/scratch/agillig/db/neurosynth/data-neurosynth_version-7_vocab-terms_source-abstract_type-tfidf_features.npz',\n",
      "                'vocabulary': '/scratch/agillig/db/neurosynth/data-neurosynth_version-7_vocab-terms_vocabulary.txt'}],\n",
      "  'metadata': '/scratch/agillig/db/neurosynth/data-neurosynth_version-7_metadata.tsv.gz'}]\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Download Neurosynth\n",
    "# -----------------------------------------------------------------------------\n",
    "# Neurosynth's data files are stored at https://github.com/neurosynth/neurosynth-data.\n",
    "out_dir = '/scratch/agillig/db'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "files = fetch_neurosynth(\n",
    "    data_dir=out_dir,\n",
    "    version=\"7\",\n",
    "    overwrite=False,\n",
    "    source=\"abstract\",\n",
    "    vocab=\"terms\",\n",
    ")\n",
    "# Note that the files are saved to a new folder within \"out_dir\" named \"neurosynth\".\n",
    "pprint(files)\n",
    "neurosynth_db = files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fetch neurosynth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nimare.dataset import Dataset\n",
    "nsynth_abstracts_dset = os.path.join(out_dir, \"neurosynth_dataset_with_abstracts.pkl.gz\")\n",
    "\n",
    "if os.path.isfile(nsynth_abstracts_dset) == False:\n",
    "    # # Convert Neurosynth database to NiMARE dataset file\n",
    "    neurosynth_dset = convert_neurosynth_to_dataset(\n",
    "        coordinates_file=neurosynth_db[\"coordinates\"],\n",
    "        metadata_file=neurosynth_db[\"metadata\"],\n",
    "        annotations_files=neurosynth_db[\"features\"],\n",
    "    )\n",
    "    neurosynth_dset.save(os.path.join(out_dir, \"neurosynth_dataset.pkl.gz\"))\n",
    "    print(neurosynth_dset)\n",
    "\n",
    "    # Add article abstracts to dataset\n",
    "    neurosynth_dset = download_abstracts(neurosynth_dset, \"example@example.edu\")\n",
    "    neurosynth_dset.save(os.path.join(out_dir, \"neurosynth_dataset_with_abstracts.pkl.gz\"))\n",
    "else:\n",
    "    neurosynth_dset = Dataset.load(nsynth_abstracts_dset)\n",
    "titles = np.array(neurosynth_dset.metadata['title'], dtype='str')\n",
    "abstracts = np.array(neurosynth_dset.texts['abstract'], dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurosynth_corpus = []\n",
    "for i in range(len(titles)):\n",
    "    concat = titles[i] + ' ' + abstracts[i]\n",
    "    neurosynth_corpus.append(concat)\n",
    "    # print(ttl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract cognitive concepts from the cognitive atlas ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from a web page\n",
    "def extract_text_from_webpage(url):\n",
    "    # Fetch the web page content\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract text from all anchor tags with href attribute\n",
    "    links = soup.find_all('a', href=True)\n",
    "    link_texts = [link.get_text() for link in links]\n",
    "\n",
    "    return link_texts\n",
    "\n",
    "# Function to extract words from text\n",
    "def extract_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    return words\n",
    "\n",
    "# Function to extract sentences from text\n",
    "def extract_sentences(text):\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "    return sentences\n",
    "\n",
    "# Example usage\n",
    "url = 'https://www.cognitiveatlas.org/concepts/categories/all'\n",
    "text = extract_text_from_webpage(url)\n",
    "# words = extract_words(text)\n",
    "# sentences = extract_sentences(text)\n",
    "\n",
    "# print(\"Words:\", words)\n",
    "# print(\"Sentences:\", sentences)\n",
    "\n",
    "# remove uppercase elements (they are not concepts but titles of html elements)\n",
    "cogatlas_concepts = [s for s in text if s and not s[0].isupper()]\n",
    "remove = ['\\n', 'cognitiveatlas NIMH Grant RO1MH082795, Russell Poldrack, PI.',\n",
    "          'cognitive control', 'theory of mind', 'language', 'working memory', 'memory']\n",
    "remove = ['\\n', 'cognitiveatlas NIMH Grant RO1MH082795, Russell Poldrack, PI.']\n",
    "cogatlas_concepts = [s for s in cogatlas_concepts if s not in remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurosynth_terms_file = project_dir + '/data/terms/BCS_3D.csv'\n",
    "os.makedirs(Path(neurosynth_terms_file).parent, exist_ok=True)\n",
    "\n",
    "# download the file from the Pacela et al. 2021 paper repo \n",
    "# https://github.com/vale-pak/BCS\n",
    "\n",
    "if not os.path.exists(neurosynth_terms_file):\n",
    "    fetch_neurosynth_data(f'{project_dir}/data')\n",
    "\n",
    "# https://github.com/vale-pak/BCS/blob/main/BCS_3D.csv\n",
    "df = pd.read_csv(neurosynth_terms_file, sep = ',')\n",
    "\n",
    "neurosynth_terms = df['Functions']\n",
    "neurosynth_terms = [s.replace('_', ' ') for s in neurosynth_terms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embed all cogatlas concepts based on tf idf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract significant terms and associated Pearson correlations for a given RSN \n",
    "import json\n",
    "corrp_file = f'{project_dir}/results/rsn_p_maxcorc_termwise.json'\n",
    "with open(corrp_file, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame.from_dict(json_data).T\n",
    "df.columns = neurosynth_terms\n",
    "\n",
    "pvals_df = df.map(lambda x: x < 0.05)\n",
    "df = pvals_df\n",
    "\n",
    "pearsonr_file = f'{project_dir}/results/rsn_Pearsonr.json'\n",
    "with open(pearsonr_file, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "pearsonr_df = pd.DataFrame.from_dict(json_data).T\n",
    "pearsonr_df.columns = neurosynth_terms\n",
    "\n",
    "cognitive_labeling_file = f'{project_dir}/results/RSN41_cognitive_labeling.xlsx'\n",
    "RSN_numbering = pd.read_excel(cognitive_labeling_file, index_col=0)['Numbering']\n",
    "df.index = RSN_numbering\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "pearsonr_df.index = RSN_numbering\n",
    "pearsonr_df.sort_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk\n",
    "import re\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "def stem_single_words_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for word in text]\n",
    "    stems = [stemmer.stem(t) for t in tokens]\n",
    "    return stems\n",
    "\n",
    "def remove_stop_words(tokens):\n",
    "    is_stopword = [any([tk == stopw for stopw in stopwords]) for tk in tokens]\n",
    "    not_stopword = [False if i == True else True for i in is_stopword]\n",
    "    cleaned_tokens = list(np.array(tokens)[np.array(not_stopword, dtype='bool')])\n",
    "    return cleaned_tokens\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /homes_unix/agillig/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /homes_unix/agillig/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stopwords = nltk.corpus.stopwords.words('english',)\n",
    "print(stopwords)\n",
    "stopwords = [tokenize_and_stem(s) for s in stopwords]\n",
    "stopwords = list(itertools.chain(*stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cogatlas_concepts = [tokenize_and_stem(s) for s in cogatlas_concepts]\n",
    "test_cogatlas_concepts = [' '.join(c) for c in test_cogatlas_concepts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(set(cogatlas_concepts).union(set(df.columns)))\n",
    "vocabulary.sort()\n",
    "tokenized_vocabulary = [tokenize_and_stem(voc) for voc in vocabulary]\n",
    "tokenized_vocabulary = list(set(itertools.chain(*tokenized_vocabulary)))\n",
    "tokenized_vocabulary.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes_unix/agillig/.conda/envs/topicmodeling/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary length: 18098\n",
      "there are 57 terms/concepts not present in the vocabulary; appending and refitting...\n",
      "performing dimensionality reduction...\n",
      "n components: 100\n"
     ]
    }
   ],
   "source": [
    "count_model = CountVectorizer(min_df=0.001, \n",
    "                              max_df=0.8, \n",
    "                              tokenizer=tokenize_and_stem, \n",
    "                              stop_words=stopwords, \n",
    "                              ngram_range=(1,2))\n",
    "count_model.fit(neurosynth_corpus)\n",
    "\n",
    "vocabulary = count_model.get_feature_names_out().tolist()\n",
    "print('vocabulary length:', len(vocabulary))\n",
    "\n",
    "\n",
    "# tokenized_cogatlas_concepts = list(set([' '.join(tokenize_and_stem(s)) for s in cogatlas_concepts]))\n",
    "# tokenized_cogatlas_onegrams = list(set(itertools.chain(*tokenized_cogatlas_concepts)))\n",
    "\n",
    "missing_onegrams = [token for token in tokenized_vocabulary if token not in count_model.vocabulary_]\n",
    "n_bigrams_absent = len(missing_onegrams)\n",
    "\n",
    "if n_bigrams_absent > 0:\n",
    "    print(f'there are {n_bigrams_absent} terms/concepts not present in the vocabulary; appending and refitting...')\n",
    "    for ngram in missing_onegrams:\n",
    "        vocabulary.append(ngram)\n",
    "    count_model = CountVectorizer(min_df=0.001, max_df=0.8, \n",
    "                                    tokenizer=tokenize_and_stem, stop_words=stopwords, ngram_range=(1,2),\n",
    "                                    vocabulary=vocabulary)\n",
    "    X = count_model.fit_transform(neurosynth_corpus)\n",
    "\n",
    "\n",
    "\n",
    "print('performing dimensionality reduction...')\n",
    "# use Truncated SVD, cf https://scikit-learn.org/stable/modules/decomposition.html#lsa\n",
    "# tfid with sublinear_tf=True, use_idf=True should be used\n",
    "tfid_transformer = TfidfTransformer(sublinear_tf=True, use_idf=True, smooth_idf=True)\n",
    "X = tfid_transformer.fit_transform(X)\n",
    "\n",
    "embedding = TruncatedSVD(n_components=100)\n",
    "X_embedded = embedding.fit_transform(X.transpose())\n",
    "\n",
    "\n",
    "neurosynth_count_embedded = pd.DataFrame(X_embedded, index=vocabulary).T\n",
    "print(f'n components: {X_embedded.shape[1]}')\n",
    "\n",
    "del X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7bcae63cc390>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(embedding.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus_from_mams(terms):\n",
    "    # for each term, get PMID of corresponding studies\n",
    "    titles = []\n",
    "    term_prefix = 'terms_abstract_tfidf__'\n",
    "    studies = []\n",
    "    coordinates = []\n",
    "    abstracts = []\n",
    "    for term in terms:\n",
    "        termstuds = neurosynth_dset.get_studies_by_label(term_prefix + term)\n",
    "        studies.append(termstuds)\n",
    "        # print(f'term {term}, {len(termstuds)} studies')\n",
    "\n",
    "    #avoid duplicate papers\n",
    "    studies_set = set()\n",
    "    for lst in studies:\n",
    "        studies_set = studies_set.union(set(lst))\n",
    "    studies = list(studies_set)\n",
    "    is_included = [any(word in s for word in studies) for s in neurosynth_dset.metadata['id']]\n",
    "    titles = list(neurosynth_dset.metadata['title'][is_included])\n",
    "    print(f'total number of articles: {len(titles)}')\n",
    "    abstracts = list(neurosynth_dset.texts['abstract'][is_included])\n",
    "    document_corpus = []\n",
    "    for i in range(len(titles)):\n",
    "        if type(abstracts[i]) == float:\n",
    "            continue\n",
    "        concat = titles[i] + ' ' + abstracts[i]\n",
    "        document_corpus.append(concat)\n",
    "    return document_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process all RSNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# tfid = TfidfTransformer(norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSN01\n",
      "RSN02\n",
      "RSN03\n",
      "Word with lowest cosine distance: visual form discrimination (distance: 0.07)\n",
      "RSN04\n",
      "Word with lowest cosine distance: speech production (distance: 0.13)\n",
      "RSN05\n",
      "Word with lowest cosine distance: memory retrieval (distance: 0.02)\n",
      "RSN06\n",
      "Word with lowest cosine distance: motor program (distance: 0.15)\n",
      "RSN07\n",
      "Word with lowest cosine distance: divergent thinking (distance: 0.30)\n",
      "RSN08\n",
      "Word with lowest cosine distance: spatial selective attention (distance: 0.02)\n",
      "RSN09\n",
      "Word with lowest cosine distance: visual masking (distance: 0.02)\n",
      "RSN10\n",
      "Word with lowest cosine distance: motor planning (distance: 0.21)\n",
      "RSN11\n",
      "Word with lowest cosine distance: nociception (distance: 0.10)\n",
      "RSN12\n",
      "Word with lowest cosine distance: analogical reasoning (distance: 0.17)\n",
      "RSN13\n",
      "Word with lowest cosine distance: decision making (distance: 0.18)\n",
      "RSN14\n",
      "Word with lowest cosine distance: auditory tone perception (distance: 0.07)\n",
      "RSN15\n",
      "Word with lowest cosine distance: language comprehension (distance: 0.10)\n",
      "RSN16\n",
      "Word with lowest cosine distance: working memory maintenance (distance: 0.05)\n",
      "RSN17\n",
      "Word with lowest cosine distance: response inhibition (distance: 0.17)\n",
      "RSN18\n",
      "Word with lowest cosine distance: expectancy (distance: 0.00)\n",
      "RSN19\n",
      "Word with lowest cosine distance: text comprehension (distance: 0.11)\n",
      "RSN20\n",
      "Word with lowest cosine distance: spatial working memory (distance: 0.15)\n",
      "RSN21\n",
      "Word with lowest cosine distance: motor planning (distance: 0.09)\n",
      "RSN22\n",
      "Word with lowest cosine distance: response conflict (distance: 0.20)\n",
      "RSN23\n",
      "Word with lowest cosine distance: working memory storage (distance: 0.04)\n",
      "RSN24\n",
      "Word with lowest cosine distance: monetary reward prediction error (distance: 0.13)\n",
      "RSN25\n",
      "Word with lowest cosine distance: movement (distance: 0.15)\n",
      "RSN26\n",
      "RSN27\n",
      "Word with lowest cosine distance: word order (distance: 0.08)\n",
      "RSN28\n",
      "Word with lowest cosine distance: inference (distance: 0.19)\n",
      "RSN29\n",
      "Word with lowest cosine distance: task difficulty (distance: 0.08)\n",
      "RSN30\n",
      "Word with lowest cosine distance: movement (distance: 0.17)\n",
      "RSN31\n",
      "Word with lowest cosine distance: cognitive control (distance: 0.11)\n",
      "RSN32\n",
      "Word with lowest cosine distance: visual object recognition (distance: 0.11)\n",
      "RSN33\n",
      "Word with lowest cosine distance: auditory sentence comprehension (distance: 0.11)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy.sparse import SparseEfficiencyWarning\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Ignore SparseEfficiencyWarning\n",
    "warnings.simplefilter('ignore', SparseEfficiencyWarning)\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "warnings.simplefilter('ignore', RuntimeWarning)\n",
    "\n",
    "\n",
    "most_central_words = {}\n",
    "min_cos_word = {}\n",
    "for i in range(1,34):\n",
    "    RSN = f'RSN{i:02d}'\n",
    "    print(RSN)\n",
    "\n",
    "    rsn_terms = df.loc[RSN, df.loc[RSN] == True].index.tolist()\n",
    "    \n",
    "    tokenized_rsn_terms = [tokenize_and_stem(term) for term in rsn_terms]\n",
    "\n",
    "\n",
    "    if len(rsn_terms) == 0:\n",
    "        continue\n",
    "\n",
    "    cosine_distances = {}\n",
    "    for cogatlas_term in cogatlas_concepts:\n",
    "        n = 0\n",
    "\n",
    "        tokenized_cogatlas_term = tokenize_and_stem(cogatlas_term)\n",
    "\n",
    "        working_rsn_terms = rsn_terms.copy()\n",
    "        \n",
    "        rsn_correlations = pearsonr_df.loc[RSN,working_rsn_terms].to_numpy()\n",
    "        rsn_correlations = np.expand_dims(rsn_correlations, axis=1)\n",
    "        weights = np.ones_like(rsn_correlations)\n",
    "\n",
    "        mean_embedding_vector = np.array([np.mean([neurosynth_count_embedded[tkn] for tkn in tkn_term], axis=0) for tkn_term in tokenized_rsn_terms])\n",
    "        mean_embedding_vector = (mean_embedding_vector * weights * rsn_correlations).mean(axis=0)\n",
    "        cogatlas_term_vector = np.mean([neurosynth_count_embedded[tkn] for tkn in tokenized_cogatlas_term], axis=0)\n",
    "        \n",
    "        if cogatlas_term_vector.ndim == 2:\n",
    "            cogatlas_term_vector = cogatlas_term_vector.ravel()\n",
    "\n",
    "        if np.sum(cogatlas_term_vector) == 0:\n",
    "            continue\n",
    "\n",
    "        cosine_distances[cogatlas_term] = cosine(cogatlas_term_vector, mean_embedding_vector)   \n",
    "    \n",
    "    cos_df = pd.DataFrame.from_dict(cosine_distances, orient='index', columns=['cosine_distance']).sort_values(by='cosine_distance', ascending=True)\n",
    "\n",
    "    \n",
    "    max_cosine_word = cos_df.iloc[0].name\n",
    "    max_cosine_value = cos_df.iloc[0].values[0]\n",
    "    print(f\"Word with lowest cosine distance: {max_cosine_word} (distance: {max_cosine_value:.2f})\")\n",
    "    min_cos_word[RSN] = max_cosine_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_central_words_df = pd.DataFrame.from_dict(most_central_words, orient='index', columns=['most_central_word'])\n",
    "min_cos_df = pd.DataFrame.from_dict(min_cos_word, orient='index', columns=['min_cos_word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts_consensus = pd.read_excel(cognitive_labeling_file, index_col=1)\n",
    "experts_consensus.sort_index(inplace=True)\n",
    "experts_consensus = experts_consensus.merge(most_central_words_df, left_index=True, right_index=True, how='outer')\n",
    "experts_consensus = experts_consensus.merge(min_cos_df, left_index=True, right_index=True, how='outer')\n",
    "compare_data_driven = experts_consensus.loc[:, ['3 closest terms (Pearson r, p)', 'anat_label', 'Cognitive Atlas label', 'min_cos_word']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3 closest terms (Pearson r, p)</th>\n",
       "      <th>anat_label</th>\n",
       "      <th>Cognitive Atlas label</th>\n",
       "      <th>data-driven Cognitive Atlas label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RSN01</th>\n",
       "      <td>mnemonic (r=0.40, p=0.07); retrieval (r=0.38, ...</td>\n",
       "      <td>pCing-medPN</td>\n",
       "      <td>n.s.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN02</th>\n",
       "      <td>monitoring (r=0.32, p=0.1); signal_task (r=0.2...</td>\n",
       "      <td>R-FTPN-03</td>\n",
       "      <td>n.s.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN03</th>\n",
       "      <td>visual (r=0.76, p&lt;0.001); visual_field (r=0.54...</td>\n",
       "      <td>ON-04</td>\n",
       "      <td>motion detection, visual object recognition</td>\n",
       "      <td>visual form discrimination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN04</th>\n",
       "      <td>speech_production (r=0.69, p&lt;0.001); oral (r=0...</td>\n",
       "      <td>PcN-02</td>\n",
       "      <td>articulation</td>\n",
       "      <td>speech production</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN05</th>\n",
       "      <td>autobiographical_memory (r=0.71, p&lt;0.001); epi...</td>\n",
       "      <td>med-TN</td>\n",
       "      <td>memory retrieval</td>\n",
       "      <td>memory retrieval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN06</th>\n",
       "      <td>foot (r=0.88, p&lt;0.001); limb (r=0.72, p&lt;0.001)...</td>\n",
       "      <td>PcN-01</td>\n",
       "      <td>movement (limb)</td>\n",
       "      <td>motor program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN07</th>\n",
       "      <td>default_mode (r=0.84, p&lt;0.001); default_networ...</td>\n",
       "      <td>med-FPN</td>\n",
       "      <td>self-referential processing</td>\n",
       "      <td>divergent thinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN08</th>\n",
       "      <td>spatial (r=0.70, p&lt;0.001); orienting (r=0.64, ...</td>\n",
       "      <td>D-FPN-03</td>\n",
       "      <td>spatial selective attention</td>\n",
       "      <td>spatial selective attention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN09</th>\n",
       "      <td>early_visual (r=0.74, p&lt;0.001); primary_visual...</td>\n",
       "      <td>ON-01</td>\n",
       "      <td>visual perception</td>\n",
       "      <td>visual masking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN10</th>\n",
       "      <td>hands (r=0.70, p&lt;0.001); action_observation (r...</td>\n",
       "      <td>D-FPN-01</td>\n",
       "      <td>motor planning</td>\n",
       "      <td>motor planning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN11</th>\n",
       "      <td>secondary_somatosensory (r=0.81, p&lt;0.001); pai...</td>\n",
       "      <td>PcN-03</td>\n",
       "      <td>somatosensation</td>\n",
       "      <td>nociception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN12</th>\n",
       "      <td>reasoning (r=0.43, p=0.02); judgments (r=0.42,...</td>\n",
       "      <td>L-FTPN-02</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>analogical reasoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN13</th>\n",
       "      <td>money (r=0.56, p&lt;0.001); preferences (r=0.50, ...</td>\n",
       "      <td>aCingN</td>\n",
       "      <td>decision making</td>\n",
       "      <td>decision making</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN14</th>\n",
       "      <td>pitch (r=0.91, p&lt;0.001); musical (r=0.88, p&lt;0....</td>\n",
       "      <td>TN-01</td>\n",
       "      <td>auditory perception</td>\n",
       "      <td>auditory tone perception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN15</th>\n",
       "      <td>verb (r=0.61, p&lt;0.001); verbs (r=0.50, p&lt;0.001...</td>\n",
       "      <td>L-FTN</td>\n",
       "      <td>syntactic processing</td>\n",
       "      <td>language comprehension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN16</th>\n",
       "      <td>memory_load (r=0.49, p=0.002); wm (r=0.40, p=0...</td>\n",
       "      <td>mCingFPN</td>\n",
       "      <td>working memory</td>\n",
       "      <td>working memory maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN17</th>\n",
       "      <td>nogo (r=0.51, p&lt;0.001); response_inhibition (r...</td>\n",
       "      <td>R-FTPN-01</td>\n",
       "      <td>self monitoring, theory of mind</td>\n",
       "      <td>response inhibition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN18</th>\n",
       "      <td>expectancy (r=0.49, p=0.002); response_inhibit...</td>\n",
       "      <td>FTPN-01</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>expectancy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN19</th>\n",
       "      <td>read (r=0.60, p&lt;0.001); sentence (r=0.58, p&lt;0....</td>\n",
       "      <td>L-FTPN-01</td>\n",
       "      <td>sentence comprehension</td>\n",
       "      <td>text comprehension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN20</th>\n",
       "      <td>calculation (r=0.58, p&lt;0.001); subtraction (r=...</td>\n",
       "      <td>R-FTPN-02</td>\n",
       "      <td>mental arithmetic</td>\n",
       "      <td>spatial working memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN21</th>\n",
       "      <td>index_finger (r=0.78, p&lt;0.001); hand_movements...</td>\n",
       "      <td>L-PcN</td>\n",
       "      <td>movement (right hand)</td>\n",
       "      <td>motor planning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN22</th>\n",
       "      <td>conflict (r=0.69, p&lt;0.001); stop_signal (r=0.5...</td>\n",
       "      <td>mCingInsN</td>\n",
       "      <td>performance monitoring</td>\n",
       "      <td>response conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN23</th>\n",
       "      <td>demands (r=0.62, p&lt;0.001); verbal (r=0.55, p=0...</td>\n",
       "      <td>L-InsFPN</td>\n",
       "      <td>phonological working memory</td>\n",
       "      <td>working memory storage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN24</th>\n",
       "      <td>gain (r=0.56, p&lt;0.001); monetary (r=0.56, p&lt;0....</td>\n",
       "      <td>BGN</td>\n",
       "      <td>reward anticipation</td>\n",
       "      <td>monetary reward prediction error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN25</th>\n",
       "      <td>hand (r=0.51, p=0.003); hands (r=0.51, p=0.004...</td>\n",
       "      <td>R-PcN</td>\n",
       "      <td>movement (left hand)</td>\n",
       "      <td>movement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN26</th>\n",
       "      <td>integrate (r=0.35, p=0.2); early_visual (r=0.2...</td>\n",
       "      <td>ON-03</td>\n",
       "      <td>n.s.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN27</th>\n",
       "      <td>arithmetic (r=0.59, p&lt;0.001); orthographic (r=...</td>\n",
       "      <td>FTPN-02</td>\n",
       "      <td>reading, mental arithmetic</td>\n",
       "      <td>word order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN28</th>\n",
       "      <td>inferences (r=0.57, p&lt;0.001); judgments (r=0.4...</td>\n",
       "      <td>med-FN</td>\n",
       "      <td>theory of mind</td>\n",
       "      <td>inference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN29</th>\n",
       "      <td>matching (r=0.52, p&lt;0.001); matching_task (r=0...</td>\n",
       "      <td>ON-02</td>\n",
       "      <td>visual form discrimination</td>\n",
       "      <td>task difficulty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN30</th>\n",
       "      <td>pointing (r=0.41, p=0.003); movements (r=0.37,...</td>\n",
       "      <td>D-FPN-02</td>\n",
       "      <td>motor imagery</td>\n",
       "      <td>movement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN31</th>\n",
       "      <td>cognitive_control (r=0.34, p=0.02); interferen...</td>\n",
       "      <td>R-FInsN</td>\n",
       "      <td>interference resolution</td>\n",
       "      <td>cognitive control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN32</th>\n",
       "      <td>motion (r=0.83, p&lt;0.001); visual_motion (r=0.7...</td>\n",
       "      <td>OTN</td>\n",
       "      <td>object perception</td>\n",
       "      <td>visual object recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSN33</th>\n",
       "      <td>comprehension (r=0.83, p&lt;0.001); sentences (r=...</td>\n",
       "      <td>TN-02</td>\n",
       "      <td>speech perception</td>\n",
       "      <td>auditory sentence comprehension</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          3 closest terms (Pearson r, p)   anat_label  \\\n",
       "RSN01  mnemonic (r=0.40, p=0.07); retrieval (r=0.38, ...  pCing-medPN   \n",
       "RSN02  monitoring (r=0.32, p=0.1); signal_task (r=0.2...    R-FTPN-03   \n",
       "RSN03  visual (r=0.76, p<0.001); visual_field (r=0.54...        ON-04   \n",
       "RSN04  speech_production (r=0.69, p<0.001); oral (r=0...       PcN-02   \n",
       "RSN05  autobiographical_memory (r=0.71, p<0.001); epi...       med-TN   \n",
       "RSN06  foot (r=0.88, p<0.001); limb (r=0.72, p<0.001)...       PcN-01   \n",
       "RSN07  default_mode (r=0.84, p<0.001); default_networ...      med-FPN   \n",
       "RSN08  spatial (r=0.70, p<0.001); orienting (r=0.64, ...     D-FPN-03   \n",
       "RSN09  early_visual (r=0.74, p<0.001); primary_visual...        ON-01   \n",
       "RSN10  hands (r=0.70, p<0.001); action_observation (r...     D-FPN-01   \n",
       "RSN11  secondary_somatosensory (r=0.81, p<0.001); pai...       PcN-03   \n",
       "RSN12  reasoning (r=0.43, p=0.02); judgments (r=0.42,...    L-FTPN-02   \n",
       "RSN13  money (r=0.56, p<0.001); preferences (r=0.50, ...       aCingN   \n",
       "RSN14  pitch (r=0.91, p<0.001); musical (r=0.88, p<0....        TN-01   \n",
       "RSN15  verb (r=0.61, p<0.001); verbs (r=0.50, p<0.001...        L-FTN   \n",
       "RSN16  memory_load (r=0.49, p=0.002); wm (r=0.40, p=0...     mCingFPN   \n",
       "RSN17  nogo (r=0.51, p<0.001); response_inhibition (r...    R-FTPN-01   \n",
       "RSN18  expectancy (r=0.49, p=0.002); response_inhibit...      FTPN-01   \n",
       "RSN19  read (r=0.60, p<0.001); sentence (r=0.58, p<0....    L-FTPN-01   \n",
       "RSN20  calculation (r=0.58, p<0.001); subtraction (r=...    R-FTPN-02   \n",
       "RSN21  index_finger (r=0.78, p<0.001); hand_movements...        L-PcN   \n",
       "RSN22  conflict (r=0.69, p<0.001); stop_signal (r=0.5...    mCingInsN   \n",
       "RSN23  demands (r=0.62, p<0.001); verbal (r=0.55, p=0...     L-InsFPN   \n",
       "RSN24  gain (r=0.56, p<0.001); monetary (r=0.56, p<0....          BGN   \n",
       "RSN25  hand (r=0.51, p=0.003); hands (r=0.51, p=0.004...        R-PcN   \n",
       "RSN26  integrate (r=0.35, p=0.2); early_visual (r=0.2...        ON-03   \n",
       "RSN27  arithmetic (r=0.59, p<0.001); orthographic (r=...      FTPN-02   \n",
       "RSN28  inferences (r=0.57, p<0.001); judgments (r=0.4...       med-FN   \n",
       "RSN29  matching (r=0.52, p<0.001); matching_task (r=0...        ON-02   \n",
       "RSN30  pointing (r=0.41, p=0.003); movements (r=0.37,...     D-FPN-02   \n",
       "RSN31  cognitive_control (r=0.34, p=0.02); interferen...      R-FInsN   \n",
       "RSN32  motion (r=0.83, p<0.001); visual_motion (r=0.7...          OTN   \n",
       "RSN33  comprehension (r=0.83, p<0.001); sentences (r=...        TN-02   \n",
       "\n",
       "                             Cognitive Atlas label  \\\n",
       "RSN01                                         n.s.   \n",
       "RSN02                                         n.s.   \n",
       "RSN03  motion detection, visual object recognition   \n",
       "RSN04                                 articulation   \n",
       "RSN05                             memory retrieval   \n",
       "RSN06                              movement (limb)   \n",
       "RSN07                  self-referential processing   \n",
       "RSN08                  spatial selective attention   \n",
       "RSN09                            visual perception   \n",
       "RSN10                               motor planning   \n",
       "RSN11                              somatosensation   \n",
       "RSN12                                    reasoning   \n",
       "RSN13                              decision making   \n",
       "RSN14                          auditory perception   \n",
       "RSN15                         syntactic processing   \n",
       "RSN16                               working memory   \n",
       "RSN17              self monitoring, theory of mind   \n",
       "RSN18                                   expectancy   \n",
       "RSN19                       sentence comprehension   \n",
       "RSN20                            mental arithmetic   \n",
       "RSN21                        movement (right hand)   \n",
       "RSN22                       performance monitoring   \n",
       "RSN23                  phonological working memory   \n",
       "RSN24                          reward anticipation   \n",
       "RSN25                         movement (left hand)   \n",
       "RSN26                                         n.s.   \n",
       "RSN27                   reading, mental arithmetic   \n",
       "RSN28                               theory of mind   \n",
       "RSN29                   visual form discrimination   \n",
       "RSN30                                motor imagery   \n",
       "RSN31                      interference resolution   \n",
       "RSN32                            object perception   \n",
       "RSN33                            speech perception   \n",
       "\n",
       "      data-driven Cognitive Atlas label  \n",
       "RSN01                               NaN  \n",
       "RSN02                               NaN  \n",
       "RSN03        visual form discrimination  \n",
       "RSN04                 speech production  \n",
       "RSN05                  memory retrieval  \n",
       "RSN06                     motor program  \n",
       "RSN07                divergent thinking  \n",
       "RSN08       spatial selective attention  \n",
       "RSN09                    visual masking  \n",
       "RSN10                    motor planning  \n",
       "RSN11                       nociception  \n",
       "RSN12              analogical reasoning  \n",
       "RSN13                   decision making  \n",
       "RSN14          auditory tone perception  \n",
       "RSN15            language comprehension  \n",
       "RSN16        working memory maintenance  \n",
       "RSN17               response inhibition  \n",
       "RSN18                        expectancy  \n",
       "RSN19                text comprehension  \n",
       "RSN20            spatial working memory  \n",
       "RSN21                    motor planning  \n",
       "RSN22                 response conflict  \n",
       "RSN23            working memory storage  \n",
       "RSN24  monetary reward prediction error  \n",
       "RSN25                          movement  \n",
       "RSN26                               NaN  \n",
       "RSN27                        word order  \n",
       "RSN28                         inference  \n",
       "RSN29                   task difficulty  \n",
       "RSN30                          movement  \n",
       "RSN31                 cognitive control  \n",
       "RSN32         visual object recognition  \n",
       "RSN33   auditory sentence comprehension  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename specific columns\n",
    "compare_data_driven = compare_data_driven.rename(columns={\n",
    "    'min_cos_word': 'data-driven Cognitive Atlas label',\n",
    "})\n",
    "compare_data_driven"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
